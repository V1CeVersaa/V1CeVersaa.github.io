# Chapter 8: 集成学习   

## 1. 个体与集成

弱学习器/Weak Learner 常指泛化性能略高于随机猜测的学习器。

在一般经验中，如果将好坏不等的东西掺杂在一起，往往得到的东西比最坏的要好一些，比最好的要坏一些；或者干脆遵循木桶短板理论。集成学习需要避免这么悲催的事情，因此我们引入多样性这一概念：

考虑二分类问题 $y \in \{-1,+1\}$ 和真实函数 $f$，假定基分类器的错误率为 $\epsilon$，即对每个基分类器 $h_i$ 有

$$P(h_i(\boldsymbol{x}) \neq f(\boldsymbol{x})) = \epsilon.$$

假设集成通过简单投票法结合 $T$ 个基分类器，若有超过半数的基分类器正确，则集成分类就正确：

$$H(\boldsymbol{x}) = \text{sign}\left(\sum_{i=1}^T h_i(\boldsymbol{x})\right).$$

假设基分类器的错误率**相互独立**，则由 Hoeffding 不等式可知，集成的错误率为

$$P(H(\boldsymbol{x}) \neq f(\boldsymbol{x})) = \sum_{k=\lfloor T/2 \rfloor + 1}^T \begin{pmatrix} T \\ k \end{pmatrix} \epsilon^k(1-\epsilon)^{T-k} \leq \exp\left(-\frac{1}{2}T(1-2\epsilon)^2\right).$$

上式显示出，随着集成中个体分类器数目 $T$ 的增大，集成的错误率将指数级下降，最终趋向于零。

但是我们有一个关键假设：基学习器的误差相互独立。在现实任务中，个体学习器是为解决同一个问题训练出来的，它们显然不可能相互独立！事实上，个体学习器的准确性和多样性本身出现冲突，一般地，准确性很高之后，要增加多样性就需牺牲准确性。如何产生并结合“好而不同”的个体学习器，是集成学习研究的核心。

根据个体学习器的生成方式，目前的集成学习方法大致可分为两大类，即个体学习器间存在强依赖关系、必须串行生成的序列化方法，以及个体学习器间不存在强依赖关系、可同时生成的并行化方法；前者的代表是 Boosting，后者的代表是 Bagging 和“随机森林”。

## 2. Boosting

**分类器权重更新公式**：

**样本更新公式**：AdaBoost 算法在获得 $H_{t-1}$ 之后样本分布进行调整，使得下一轮的基学习器 $h_t$ 能纠正 $H_{t-1}$ 的一些错误，理想的 $h_t$ 能纠正 $H_{t-1}$ 的全部错误，即最小化：

$$\begin{aligned}
\ell_{\exp}(H_{t-1}+h_t|\mathcal{D}) &= \mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)(H_{t-1}(x)+h_t(x))}] \\
&= \mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)H_{t-1}(x)}e^{-f(x)h_t(x)}]
\end{aligned}$$

注意到 $f^2(x)=h_t^2(x)=1$，上式可使用 $e^{-f(x)h_t(x)}$ 的泰勒展式近似为：

$$\begin{aligned}
\ell_{\exp}(H_{t-1}+h_t|\mathcal{D}) &= \mathbb{E}_{x\sim\mathcal{D}}\left[e^{-f(x)H_{t-1}(x)}\left(1-f(x)h_t(x)+\frac{f^2(x)h_t^2(x)}{2}\right)\right] \\
&= \mathbb{E}_{x\sim\mathcal{D}}\left[e^{-f(x)H_{t-1}(x)}\left(1-f(x)h_t(x)+\frac{1}{2}\right)\right]
\end{aligned}$$

于是，理想的基学习器满足：

$$\begin{aligned}
h_t(x) &= \arg\min_h \ell_{\exp}(H_{t-1}+h|\mathcal{D}) \\
&= \arg\min_h \mathbb{E}_{x\sim\mathcal{D}}\left[e^{-f(x)H_{t-1}(x)}\left(1-f(x)h(x)+\frac{1}{2}\right)\right] \\
&= \arg\max_h \mathbb{E}_{x\sim\mathcal{D}}\left[e^{-f(x)H_{t-1}(x)}f(x)h(x)\right] \\
&= \arg\max_h \mathbb{E}_{x\sim\mathcal{D}}\left[\frac{e^{-f(x)H_{t-1}(x)}}{\mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)H_{t-1}(x)}]}f(x)h(x)\right] \\
&= \arg\max_h \mathbb{E}_{x\sim\mathcal{D}_t}[f(x)h(x)]
\end{aligned}$$

注意到 $\mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)H_{t-1}(x)}]$ 是一个常数，所以 $\mathcal{D}_t$ 为下面的分布：

$$\mathcal{D}_t(x) = \frac{\mathcal{D}(x)e^{-f(x)H_{t-1}(x)}}{\mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)H_{t-1}(x)}]}$$


<!-- 

Boosting 是一族可将弱学习器提升为强学习器的算法。这族算法的工作机制类似：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注；然后基于调整后的样本分布来训练下一个基学习器；如此重复进行，直至基学习器数目达到事先指定的值 $T$，最终将这 $T$ 个基学习器进行加权结合。

Boosting 族算法最著名的代表是 AdaBoost [Freund and Shapire, 1997]，其描述如图 8.3 所示，其中 $y_i \in \{-1,+1\}$，$f$ 是真实函数。

AdaBoost 算法有多种推导方式，比较容易理解的是基于"加性模型"(additive model)，即基学习器的线性组合：

$$H(x) = \sum_{t=1}^T \alpha_th_t(x)$$ (8.4)

来最小化指数损失函数(exponential loss function) [Friedman et al., 2000]：

$$\ell_{\exp}(H|\mathcal{D}) = \mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)H(x)}]$$ (8.5)

若 $H(x)$ 能令指数损失函数最小化，则考虑式(8.5)对 $H(x)$ 的偏导：

$$\frac{\partial \ell_{\exp}(H|\mathcal{D})}{\partial H(x)} = -e^{-H(x)}P(f(x)=1|x) + e^{H(x)}P(f(x)=-1|x)$$ (8.6)

令式(8.6)为零可解得：

$$H(x) = \frac{1}{2}\ln\frac{P(f(x)=1|x)}{P(f(x)=-1|x)}$$ (8.7)

因此，有：

$$\begin{aligned}
\text{sign}(H(x)) &= \text{sign}\left(\frac{1}{2}\ln\frac{P(f(x)=1|x)}{P(f(x)=-1|x)}\right) \\
&= \begin{cases}
1, & P(f(x)=1|x) > P(f(x)=-1|x) \\
-1, & P(f(x)=1|x) < P(f(x)=-1|x)
\end{cases} \\
&= \arg\max_{y\in\{-1,1\}}P(f(x)=y|x)
\end{aligned}$$ (8.8)

这意味着 $\text{sign}(H(x))$ 达到了贝叶斯最优错误率。换言之，若指数损失函数最小化，则分类错误率也将最小化；这说明指数损失函数是分类任务 0/1 损失函数的一致性(consistent)替代损失函数。由于这个替代函数有很好的数学性质，因此我们用它替代 0/1 损失函数作为优化目标。

在 AdaBoost 算法中，第一个基分类器 $h_1$ 是通过直接将基学习算法用于初始数据分布而得；此后迭代地生成 $h_t$ 和 $\alpha_t$，当基分类器 $h_t$ 基于分布 $\mathcal{D}_t$ 产生后，该基分类器的权重 $\alpha_t$ 应使得 $\alpha_th_t$ 最小化指数损失函数：

$$\begin{aligned}
\ell_{\exp}(\alpha_th_t|\mathcal{D}_t) &= \mathbb{E}_{x\sim\mathcal{D}_t}\left[e^{-f(x)\alpha_th_t(x)}\right] \\
&= \mathbb{E}_{x\sim\mathcal{D}_t}\left[e^{-\alpha_t}\mathbb{1}(f(x)=h_t(x)) + e^{\alpha_t}\mathbb{1}(f(x)\neq h_t(x))\right] \\
&= e^{-\alpha_t}P_{x\sim\mathcal{D}_t}(f(x)=h_t(x)) + e^{\alpha_t}P_{x\sim\mathcal{D}_t}(f(x)\neq h_t(x)) \\
&= e^{-\alpha_t}(1-\epsilon_t) + e^{\alpha_t}\epsilon_t
\end{aligned}$$ (8.9)

其中 $\epsilon_t = P_{x\sim\mathcal{D}_t}(h_t(x)\neq f(x))$。考虑指数损失函数的导数：

$$\frac{\partial \ell_{\exp}(\alpha_th_t|\mathcal{D}_t)}{\partial \alpha_t} = -e^{-\alpha_t}(1-\epsilon_t) + e^{\alpha_t}\epsilon_t$$ (8.10)

令式(8.10)为零可解得：

$$\alpha_t = \frac{1}{2}\ln\left(\frac{1-\epsilon_t}{\epsilon_t}\right)$$ (8.11)

这恰是图 8.3 中算法第 6 行的分类器权重更新公式。

AdaBoost 算法在获得 $H_{t-1}$ 之后样本分布进行调整，使下一轮的基学习器 $h_t$ 能纠正 $H_{t-1}$ 的一些错误，理想的 $h_t$ 能纠正 $H_{t-1}$ 的全部错误，即最小化：

$$\begin{aligned}
\ell_{\exp}(H_{t-1}+h_t|\mathcal{D}) &= \mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)(H_{t-1}(x)+h_t(x))}] \\
&= \mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)H_{t-1}(x)}e^{-f(x)h_t(x)}]
\end{aligned}$$ (8.12)

注意到 $f^2(x)=h_t^2(x)=1$，式(8.12)可使用 $e^{-f(x)h_t(x)}$ 的泰勒展式近似为：

$$\begin{aligned}
\ell_{\exp}(H_{t-1}+h_t|\mathcal{D}) &= \mathbb{E}_{x\sim\mathcal{D}}\left[e^{-f(x)H_{t-1}(x)}\left(1-f(x)h_t(x)+\frac{f^2(x)h_t^2(x)}{2}\right)\right] \\
&= \mathbb{E}_{x\sim\mathcal{D}}\left[e^{-f(x)H_{t-1}(x)}\left(1-f(x)h_t(x)+\frac{1}{2}\right)\right]
\end{aligned}$$ (8.13)

于是，理想的基学习器：

$$\begin{aligned}
h_t(x) &= \arg\min_h \ell_{\exp}(H_{t-1}+h|\mathcal{D}) \\
&= \arg\min_h \mathbb{E}_{x\sim\mathcal{D}}\left[e^{-f(x)H_{t-1}(x)}\left(1-f(x)h(x)+\frac{1}{2}\right)\right] \\
&= \arg\max_h \mathbb{E}_{x\sim\mathcal{D}}\left[e^{-f(x)H_{t-1}(x)}f(x)h(x)\right] \\
&= \arg\max_h \mathbb{E}_{x\sim\mathcal{D}}\left[\frac{e^{-f(x)H_{t-1}(x)}}{\mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)H_{t-1}(x)}]}f(x)h(x)\right]
\end{aligned}$$ (8.14)

注意到 $\mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)H_{t-1}(x)}]$ 是一个常数。令 $\mathcal{D}_t$ 表示一个分布：

$$\mathcal{D}_t(x) = \frac{\mathcal{D}(x)e^{-f(x)H_{t-1}(x)}}{\mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)H_{t-1}(x)}]}$$ (8.15)

则根据基学习器的定义，这等价于：

$$\begin{aligned}
h_t(x) &= \arg\max_h \mathbb{E}_{x\sim\mathcal{D}}\left[\frac{e^{-f(x)H_{t-1}(x)}}{\mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)H_{t-1}(x)}]}f(x)h(x)\right] \\
&= \arg\max_h \mathbb{E}_{x\sim\mathcal{D}_t}[f(x)h(x)]
\end{aligned}$$ (8.16)

由 $f(x),h(x) \in \{-1,+1\}$，有：

$$f(x)h(x) = 1-2\mathbb{1}(f(x)\neq h(x))$$ (8.17)

则理想的基学习器：

$$h_t(x) = \arg\min_h \mathbb{E}_{x\sim\mathcal{D}_t}[\mathbb{1}(f(x)\neq h(x))]$$ (8.18) 
由此可见，理想的 $h_t$ 将在分布 $\mathcal{D}_t$ 下最小化分类误差。因此，弱分类器将基于分布 $\mathcal{D}_t$ 来训练，且对于 $\mathcal{D}_t$ 的分类误差应小于 0.5。这在一定程度上类似"残差逼近"的想法。考虑到 $\mathcal{D}_t$ 和 $\mathcal{D}_{t+1}$ 的关系，有：

$$\begin{aligned}
\mathcal{D}_{t+1}(x) &= \frac{\mathcal{D}(x)e^{-f(x)H_t(x)}}{\mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)H_t(x)}]} \\
&= \frac{\mathcal{D}(x)e^{-f(x)H_{t-1}(x)}e^{-f(x)\alpha_th_t(x)}}{\mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)H_t(x)}]} \\
&= \mathcal{D}_t(x) \cdot e^{-f(x)\alpha_th_t(x)}\frac{\mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)H_{t-1}(x)}]}{\mathbb{E}_{x\sim\mathcal{D}}[e^{-f(x)H_t(x)}]}
\end{aligned}$$ (8.19)

这恰是图 8.3 中算法第 7 行的样本分布更新公式。

主要地，由式(8.11)和(8.19)可见，我们从基于加性模型和优化指数损失函数的角度推导出了 AdaBoost 算法。

### 2.1 实现方法

Boosting 算法要求基学习器能对特定的数据分布进行学习，这可以通过以下两种方法实现：

1. **重赋权法** (re-weighting)：
   - 在训练过程的每一轮中，根据样本分布为每个训练样本重新赋予一个权重

2. **重采样法** (re-sampling)：
   - 在每一轮学习中，根据样本分布对训练集重新进行采样
   - 用重采样得到的样本集对基学习器进行训练

一般而言，这两种方法没有显著的优劣差别。

### 2.2 算法特点

1. **基本条件检查**：
   - Boosting 算法在训练的每一轮都要检查当前生成的基学习器是否满足基本条件（例如图 8.3 的第 5 行，检查当前错误率是否小于 0.5）
   - 一旦条件不满足，则当前基学习器即被抛弃，且学习过程停止

2. **实现方法的影响**：
   - 使用"重采样法"时，如果过早停止可能导致最终集成包含很少的基学习器而性能不佳
   - 使用"重赋权法"时，可获得"重启动"机会 [Kohavi and Wolpert, 1996]：
     - 在抛弃不满足条件的当前基学习器之后
     - 可根据当前分布重新对训练样本进行采样
     - 再基于新的采样结果重新训练出基学习器
     - 从而使得学习过程可以持续到预设的 $T$ 轮完成

3. **偏差-方差分解角度**：
   - Boosting 主要关注降低偏差
   - 因此 Boosting 能基于泛化性能相当弱的学习器构建出很强的集成
   - 例如：以决策树为例，在表 4.5 的西瓜数据集 3.0α 上运行 AdaBoost 算法，不同规模(size)的集成及其基学习器所对应的分类边界如图 8.4 所示

-->

## 3. Bagging 与随机森林

欲得到泛化性能强的集成，集成中的个体学习器应该尽可能相互独立，虽然独立在现实任务中无法做到，但是可以设法使基学习器尽可能具有较大的差异。给定一个训练数据集，一种可能的做法是对训练样本进行采样，产生出若干个不同的子集，再从每个数据子集中训练出一个基学习器。这样，由于训练数据不同，我们获得的基学习器可望具有比较大的差异。然而，为获得好的集成，我们同时还希望个体学习器不能太差。如果采样出的每个子集都完全不同，则每个基学习器只用到了一小部分训练数据，甚至不足以进行有效学习，这显然无法确保产生出比较好的基学习器。为解决这个问题，我们考虑使用相互有交叠的采样子集。

### 3.1 Bagging

Bagging 方法是并行式集成学习方法最著名的代表，基于自助采样法/Bosstrap Sampling。给定包含 $m$ 个样本的数据集，我们先随机取出一个样本放入采样集中，再把该样本放回初始数据集，使得下次采样时该样本仍有可能被选中，这样，经过 $m$ 次随机采样操作，我们得到含 $m$ 个样本的采样集。初始训练集中大约有 63.2% 的样本出现在采样集中。

照这样，我们可采样出 $T$ 个含 $m$ 个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器进行结合。这就是 Bagging 的基本流程。在对预测输出进行结合时，Bagging 通常对分类任务使用简单投票法，对回归任务使用简单平均法。若分类预测时出现两个类收到同样票数的情形，则最简单的做法是随机选择一个，也可进一步考察学习器投票的置信度来确定最终胜者。

Bagging 的算法描述如下：

<img class="center-picture" src="../assets/8-3.png" width="650" />

假定基学习器的计算复杂度为 $O(m)$，采样和投票的复杂度为 $O(s)$，则 Bagging 的复杂度大致为 $T(O(m) + O(s))$，考虑到采样与投票的复杂度 $O(s)$ 很小，而 $T$ 通常是一个不太大的常数，因此，训练一个 Bagging 集成与直接使用基学习算法训练一个学习器的复杂度同阶，这说明 Bagging 是一个很高效的集成学习算法。另外，与标准 AdaBoost 只适用于二分类任务不同，Bagging 能不经修改地用于多分类和回归任务。

除此之外，自助采样还可以用于 Bagging 泛化误差的估计。不妨令 $D_t$ 表示第 $t$ 个基学习器实际使用的训练样本集，令 $H^{oob}(x)$ 表示对样本 $x$ 的包外预测，即仅考虑那些未使用 $x$ 训练的基学习器在 $x$ 上的预测，有：

$$H^{oob}(x) = \underset{y\in\mathcal{Y}}{\arg\max}\sum_{t=1}^T \mathbb{1}(h_t(x)=y) \cdot \mathbb{1}(x \notin D_i)$$

则 Bagging 泛化误差的包外估计为：

$$\epsilon^{oob} = \frac{1}{|D|}\sum_{(x,y)\in D}\mathbb{1}(H^{oob}(x) \neq y)$$

除此之外，包外样本还有许多其他用途。例如当基学习器是决策树时，可使用包外样本来辅助剪枝，或用于估计决策树中各结点的后验概率以辅助对零训练样本结点的处理；当基学习器是神经网络时，可使用包外样本来辅助早期停止以减小过拟合风险。

### 3.2 随机森林

<!-- 
### 3.2 随机森林

随机森林(Random Forest，简称 RF) [Breiman, 2001a] 是 Bagging 的一个扩展变体。RF 在以决策树为基学习器构建 Bagging 集成的基础上，进一步在决策树的训练过程中引入了随机属性选择。具体来说，传统决策树在选择划分属性时是在当前结点的属性集合（假定有 $d$ 个属性）中选择一个最优属性；而在 RF 中，对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含 $k$ 个属性的子集，然后再从这个子集中选择一个最优属性用于划分。这里的参数 $k$ 控制了随机性的引入程度：若令 $k = d$，则基决策树的构建与传统决策树相同；若令 $k = 1$，则是随机选择一个属性用于划分；一般情况下，推荐值 $k = \log_2d$ [Breiman, 2001a]。

随机森林简单、容易实现、计算开销小，令人惊奇的是，它在很多现实任务中展现出强大的性能，被誉为"代表集成学习技术水平的方法"。可以看出，随机森林对 Bagging 只做了小改动，但是与 Bagging 中基学习器的"多样性"仅通过样本扰动（通过对初始训练集采样）而来不同，随机森林中基学习器的多样性不仅来自样本扰动，还来自属性扰动，这使得最终集成的泛化性能可通过个体学习器之间差异度的增加而进一步提升。

随机森林的收敛性与 Bagging 相似。如图 8.7 所示，随机森林的起始性能往往相对较差，特别是在集成中只包含一个基学习器时；这很容易理解，因为通过引入属性扰动，随机森林中个体学习器的性能往往有所降低。然而，随着个体学习器数目的增加，随机森林通常会收敛到更低的泛化误差。值得一提的是，随机森林的训练效率常优于 Bagging，因为在个体决策树的构建过程中，Bagging 使用的是"确定型"决策树，在选择划分属性时要对结点的所有属性进行考察，而随机森林使用的"随机型"决策树则只需考察一个属性子集。 -->

## 4. 结合策略

<!-- ## 4. 结合策略

学习器结合可能会从三个方面带来好处 [Dietterich, 2000]：首先，从统计的方面来看，由于学习任务的假设空间往往很大，可能有多个假设在训练集上达到相同等性能，此时若使用单学习器可能因误选而导致泛化性能不佳，结合多个学习器则会减小这一风险；第二，从计算的方面来看，学习算法往往会陷入局部极小，有的局部极小点所对应的泛化性能可能很糟糕，而通过多次运行之后进行结合，可降低陷入糟糕局部极小点的风险；第三，从表示的方面来看，某些学习任务的真实假设可能不在当前学习算法所考虑的假设空间中，此时若使用单学习器则肯定无效，而通过结合多个学习器，由于相应的假设空间有所扩大，有可能学习到更好的近似。图 8.8 给出了一个直观示意图。

假定集成包含 $T$ 个基学习器 $\{h_1,h_2,\ldots,h_T\}$，其中 $h_i$ 在示例 $x$ 上的输出为 $h_i(x)$。本节介绍几种对 $h_i$ 进行结合的常见策略。

### 4.1 平均法

对数值型输出 $h_i(x) \in \mathbb{R}$，最常见的结合策略是使用平均法(averaging)。

- 简单平均法(simple averaging)：

$$H(x) = \frac{1}{T}\sum_{i=1}^T h_i(x)$$ (8.22)

- 加权平均法(weighted averaging)：

$$H(x) = \sum_{i=1}^T w_ih_i(x)$$ (8.23)

其中 $w_i$ 是个体学习器 $h_i$ 的权重，通常要求 $w_i \geq 0$，$\sum_{i=1}^T w_i = 1$。

显然，简单平均法是加权平均法令 $w_i = 1/T$ 的特例。加权平均法在二十世纪末被广泛用于神经网络集成 [Perrone and Cooper, 1993]，近年来在集成学习中也颇受关注。它在集成学习中具有特别的意义，集成学习中的各种结合方法都可视为加权平均法的特例或变体。事实上，加权平均法可以看为是集成学习研究的一个基本出发点，对给定的基学习器，不同的集成学习方法可视为通过不同的方式来确定加权平均法中的基学习器权重。

加权平均法的权重一般是从训练数据中学习得到，现实任务中的训练样本通常不充分或存在噪声，这将使得学习出的权重不完全可靠。尤其是对规模比较大的集成来说，要学习的权重比较多，这时过拟合的风险比较大。因此，实验和理论研究都显示出，在个体学习器性能相差不大时宜使用简单平均法，而在个体学习器性能相差较大时则宜使用加权平均法。

### 4.2 投票法

对分类任务来说，学习器 $h_i$ 将从类别标记集合 $\{c_1,c_2,\ldots,c_N\}$ 中预测出一个标记。为便于讨论，我们把 $h_i$ 在样本 $x$ 上的预测输出表示为一个 $N$ 维向量 $(h_i^1(x);h_i^2(x);\ldots;h_i^N(x))$，其中 $h_i^j(x)$ 是 $h_i$ 在类别标记 $c_j$ 上的输出。

- 绝对多数投票法(majority voting)：

$$H(x) = \begin{cases}
c_j, & \text{if } \sum_{i=1}^T h_i^j(x) > 0.5\sum_{k=1}^N\sum_{i=1}^T h_i^k(x); \\
\text{reject}, & \text{otherwise}.
\end{cases}$$ (8.24)

即若某标记得票过半数则预测为该标记；否则拒绝预测。

- 相对多数投票法(plurality voting)：

$$H(x) = c_{\arg\max_j\sum_{i=1}^T h_i^j(x)}$$ (8.25) 
即预测为得票最多的标记，若同时有多个标记获得最高票，则从中随机选取一个。

- 加权投票法(weighted voting)：

$$H(x) = c_{\arg\max_j\sum_{i=1}^T w_ih_i^j(x)}$$ (8.26)

与加权平均法类似，$w_i$ 是 $h_i$ 的权重，通常要求 $w_i \geq 0$，$\sum_{i=1}^T w_i = 1$。

标准的绝对多数投票法(8.24)提供了"拒绝预测"选项，这在一些任务中是有意义的。但若必须做出预测，则可将绝对多数投票法的"拒绝预测"替换为相对多数投票法的结果。因此，在不允许拒绝预测的任务中，绝对多数投票法将蜕化为相对多数投票法。

式(8.24)～(8.26)有限制个体学习器输出的类型。在现实任务中，不同类型的个体学习器可能产生不同类型的 $h_i^j(x)$ 值，常见的有：

- 类标记：$h_i^j(x) \in \{0,1\}$，若 $h_i$ 将样本 $x$ 预测为类别 $c_j$ 则取值为 1，否则为 0。使用类标记的投票亦称"硬投票"(hard voting)。

- 类概率：$h_i^j(x) \in [0,1]$，相当于对后验概率 $P(c_j|x)$ 的一个估计。使用类概率的投票亦称"软投票"(soft voting)。

不同类型的 $h_i^j(x)$ 值不能混用。对一些能在预测出类别标记的同时产生分类置信度的学习器，其分类置信度可转化为类概率使用。若此类值未进行归一化，例如支持向量机的分类间隔值，则需使用一些技术如 Platt 缩放(Platt scaling) [Platt, 2000]、等分回归(isotonic regression) [Zadrozny and Elkan, 2001]等进行校准(calibration)后才能作为类概率使用。有趣的是，虽然分类器给出的类概率值一般都不太准确，但基于类概率进行结合却往往比基于类标记进行结合性能更好。需要注意的是，对不同的基学习器的类型不同，则其类概率值不能直接进行比较；在此种情形下，通常可将类概率输出转化为类标记输出(例如将类概率输出最大的 $h_i^j(x)$ 设为 1，其他设为 0) 然后再投票。

### 4.3 学习法

当训练数据很多时，一种更为强大的结合策略是使用"学习法"，即通过另一个学习器来进行结合。Stacking [Wolpert, 1992; Breiman, 1996b] 是学习法的典型代表。这里我们把个体学习器称为初级学习器，用于结合的学习器称为次级学习器或元学习器(meta-learner)。

Stacking 先从初始数据集训练出初级学习器，然后"生成"一个新数据集用于训练次级学习器。在这个新数据集中，初级学习器的输出被当作样例输入特征，而初始样本的标记仍被当作样例标记。Stacking 的算法描述如图 8.9 所示，这里我们假定初级学习器使用不同学习算法产生，即初级学习器是异质的。

!!! Info "图 8.9 Stacking 算法"
    输入：训练集 $D = \{(x_1,y_1),(x_2,y_2),\ldots,(x_m,y_m)\}$；
         初级学习算法 $\mathcal{L}_1,\mathcal{L}_2,\ldots,\mathcal{L}_T$；
         次级学习算法 $\mathcal{L}$

    过程：
    1. **for** $t=1,2,\ldots,T$ **do**
    2. $h_t = \mathcal{L}_t(D)$;
    3. **end for**
    4. $D' = \emptyset$;
    5. **for** $i=1,2,\ldots,m$ **do**
    6. &emsp;**for** $t=1,2,\ldots,T$ **do**
    7. &emsp;&emsp;$z_{it} = h_t(x_i)$;
    8. &emsp;**end for**
    9. &emsp;$D' = D' \cup \{((z_{i1},z_{i2},\ldots,z_{iT}),y_i)\}$;
    10. **end for**
    11. $h' = \mathcal{L}(D')$;

    输出：$H(x) = h'(h_1(x),h_2(x),\ldots,h_T(x))$

在训练阶段，次级训练集是利用初级学习器产生的，若直接用初级学习器的训练集来产生次级训练集，过拟合风险会比较大；因此，一般是通过使用交叉验证法或留一法这样的方式，用训练初级学习器未使用的样本来产生次级学习器的训练样本。以 $k$ 折交叉验证为例，初始训练集 $D$ 被随机划分为 $k$ 个大小相似的集合 $D_1,D_2,\ldots,D_k$，令 $D_j$ 和 $\bar{D}_j = D\setminus D_j$ 分别表示第 $j$ 折的测试集和训练集。给定 $T$ 个初级学习算法，初级学习器 $h_t^j$ 通过在 $D_j$ 上使用第 $t$ 个学习算法得到，令 $z_{it} = h_t^j(x_i)$，则由所产生的次级训练样本的示例分为 $z_i = (z_{i1};z_{i2};\ldots;z_{iT})$，标记部分为 $y_i$。于是，在整个交叉验证过程结束后，从这 $T$ 个初级学习器产生的次级训练集是 $D' = \{(z_i,y_i)\}_{i=1}^m$，然后 $D'$ 将用于训练次级学习器。

次级学习器的输入属性表示和次级学习算法对 Stacking 集成的泛化性能有很大影响。有研究表明，将初级学习器的输出类概率作为次级学习器的输入属性，用多响应线性回归(Multi-response Linear Regression，简称 MLR) 作为次级学习算法效果较好 [Ting and Witten, 1999]，在 MLR 中使用不同的属性集更佳 [Seewald, 2002]。

贝叶斯模型平均(Bayes Model Averaging，简称 BMA)基于后验概率来为不同模型赋予权重，可视为加权平均法的一种特殊实现。[Clarke, 2003] 对 Stacking 和 BMA 进行了比较。理论上来说，若数据生成模型恰在当前考虑的模型中，且数据噪声很小，则 BMA 不差于 Stacking；然而，在现实应用中无法确保数据生成模型一定在当前考虑的模型中，甚至可能难以用当前考虑的模型来进行近似，因此，Stacking 通常优于 BMA，因为其更具鲁棒性且 BMA 对模型近似误差更敏感。-->

## 5. 多样性

### 5.1 误差-分歧分解

欲得到泛化性能强的集成，个体学习器应好而不同，

### 5.2 多样性度量

<!-- ### 5.1 误差-分歧分解

8.1 节提到，欲得到泛化性能强的集成，个体学习器应"好而不同"。现在我们来做一个简单的理论分析。

假定我们用个体学习器 $h_1,h_2,\ldots,h_T$ 通过加权平均法(8.23)结合产生集成来完成回归学习任务 $f: \mathbb{R}^d \mapsto \mathbb{R}$。对示例 $x$，定义学习器 $h_i$ 的"分歧"(ambiguity)为

$$A(h_i|x) = (h_i(x)-H(x))^2,$$ (8.27)

则集成的"分歧"是

$$\bar{A}(h|x) = \sum_{i=1}^T w_iA(h_i|x) = \sum_{i=1}^T w_i(h_i(x)-H(x))^2.$$ (8.28)

显然，这里的"分歧"项表征了个体学习器在样本 $x$ 上的不一致性，即在一定程度上反映了个体学习器的多样性。个体学习器 $h_i$ 和集成 $H$ 的平方误差分别为

$$E(h_i|x) = (f(x)-h_i(x))^2,$$ (8.29)

$$E(H|x) = (f(x)-H(x))^2.$$ (8.30)

令 $\bar{E}(h|x) = \sum_{i=1}^T w_i \cdot E(h_i|x)$ 表示个体学习器误差的加权均值，有

$$\bar{A}(h|x) = \sum_{i=1}^T w_iE(h_i|x) - E(H|x) = \bar{E}(h|x) - E(H|x).$$ (8.31)

式(8.31)对所有样本 $x$ 均成立。令 $p(x)$ 表示样本的概率密度，则在全样本上有

$$\sum_{i=1}^T w_i\int A(h_i|x)p(x)dx = \sum_{i=1}^T w_i\int E(h_i|x)p(x)dx - \int E(H|x)p(x)dx.$$ (8.32)

类似的，个体学习器 $h_i$ 在全样本上的泛化误差和分歧分别为

$$E_i = \int E(h_i|x)p(x)dx,$$ (8.33)

$$A_i = \int A(h_i|x)p(x)dx.$$ (8.34)

集成的泛化误差为

$$E = \int E(H|x)p(x)dx.$$ (8.35)

将式(8.33)～(8.35)代入式(8.32)，再令 $\bar{E} = \sum_{i=1}^T w_iE_i$ 表示个体学习器泛化误差的加权均值，$\bar{A} = \sum_{i=1}^T w_iA_i$ 表示个体学习器的加权分歧值，有

$$E = \bar{E} - \bar{A}.$$ (8.36)

式(8.36)这个漂亮的式子明确地显示出：个体学习器准确性越高、多样性越大，则集成越好。上面这个分析早由 [Krogh and Vedelsby, 1995] 给出，称为"误差-分歧分解"(error-ambiguity decomposition)。

至此，读者可能很高兴：我们直接把 $\bar{E} - \bar{A}$ 作为优化目标来求解，不就能得到最优的集成了？遗憾的是，在现实任务中很难直接对 $\bar{E} - \bar{A}$ 进行优化，不仅由于它们是定义在整个样本空间上，还由于 $\bar{A}$ 不是一个可直接操作的多样性度量。此外需注意的是，上面的推导过程只适用于回归，难以直接推广到分类任务上去。

### 5.2 多样性度量

顾名思义，多样性度量(diversity measure)用于度量集成中个体分类器的多样性，即估算个体分类器的多样化程度。典型做法是考虑个体分类器的两两相似/不相似性。

给定数据集 $D = \{(x_1,y_1),(x_2,y_2),\ldots,(x_m,y_m)\}$，对二分类任务，$y_i \in \{-1,+1\}$，分类器 $h_i$ 与 $h_j$ 的预测结果列联表(contingency table)为

|            | $h_i = +1$ | $h_i = -1$ |
| ---------- | ---------- | ---------- |
| $h_j = +1$ | $a$        | $c$        |
| $h_j = -1$ | $b$        | $d$        |

其中，$a$ 表示 $h_i$ 与 $h_j$ 均预测为正类的样本数目；$b$、$c$、$d$ 各自由此类推；$a+b+c+d=m$。基于这个列联表，下面给出一些常见的多样性度量。

- 不合度量(disagreement measure)：

$$dis_{ij} = \frac{b+c}{m}.$$ (8.37)

$dis_{ij}$ 的值域为 [0,1]，值越大则多样性越大。

- 相关系数(correlation coefficient)：

$$\rho_{ij} = \frac{ad-bc}{\sqrt{(a+b)(a+c)(c+d)(b+d)}}.$$ (8.38)

$\rho_{ij}$ 的值域为 [-1,1]，若 $h_i$ 与 $h_j$ 无关，则值为 0；若 $h_i$ 与 $h_j$ 正相关则值为正，否则为负。

- $Q$-统计量($Q$-statistic)：

$$Q_{ij} = \frac{ad-bc}{ad+bc}.$$ (8.39)

$Q_{ij}$ 与相关系数 $\rho_{ij}$ 的符号相同，且 $|Q_{ij}| \leq |\rho_{ij}|$。

- $\kappa$-统计量($\kappa$-statistic)：

$$\kappa = \frac{p_1-p_2}{1-p_2}.$$ (8.40)

其中，$p_1$ 是两个分类器取得一致的概率，$p_2$ 是两个分类器偶然达成一致的概率，它们可由数据集 $D$ 计算：

$$p_1 = \frac{a+d}{m},$$ (8.41)

$$p_2 = \frac{(a+b)(a+c)+(c+d)(b+d)}{m^2}.$$ (8.42)

若分类器 $h_i$ 与 $h_j$ 在 $D$ 上完全一致，则 $\kappa = 1$；若它们仅是偶然达成一致，则 $\kappa = 0$。 
则 $\kappa = 0$。$\kappa$ 通常为非负值，仅在 $h_i$ 与 $h_j$ 达成一致的概率甚至低于偶然性的情况下取负值。

以上介绍的都是"成对型"(pairwise)多样性度量，它们可以容易地通过 2 维图绘制出来。例如著名的"$\kappa$-误差图"，就是将每一对分类器作为图上的一个点，横坐标是这对分类器的 $\kappa$ 值，纵坐标是它们的平均误差，图 8.10 给出了一个例子。显然，数据点云的位置越低，则个体分类器准确性越高；点云的位置越靠左，则个体学习器的多样性越大。
-->

### 5.3 多样性增强

- **数据样本扰动**：给定初始数据集，可以从中产生出不同的数据子集，再利用不同的数据子集训练出不同的个体学习器。数据样本扰动通常是基于采样法，例如在 Bagging 中使用自助采样，在 AdaBoost 中使用序列采样。数据样本扰动对于神经网络、决策树等易受样本扰动的学习器特别有效。
- **输入属性扰动**：
- **输出表示扰动**：
- **算法参数扰动**：

<!-- ### 5.3 多样性增强

在集成学习中需有效地生成多样性大的个体学习器。与简单地直接使用初始数据训练出个体学习器相比，如何增强多样性呢？一般思路是在学习过程中引入随机性，常见做法主要是对数据样本、输入属性、输出表示、算法参数进行扰动。

- 输入属性扰动

训练样本通常由一组属性描述，不同的"子空间"(subspace，即属性子集)提供了观察数据的不同视角，显然，从不同子空间训练出的个体学习器必然有所不同。著名的随机子空间算法 [Ho, 1998] 就是基于这样的思想。如图 8.11 所示，对包含大量冗余属性的数据，在子空间中训练个体学习器不仅能产生多样性大的个体，还会因属性数的减少而大幅降低学习时间开销；同时，由于冗余属性的存在，减少一些属性后训练出的个体学习器也不会太差。若数据只包含少量属性，或者属性非冗余，则不宜使用输入属性扰动法。

!!! Info "图 8.11 随机子空间算法"
    输入：训练集 $D = \{(x_1,y_1),(x_2,y_2),\ldots,(x_m,y_m)\}$；
         基学习算法 $\mathcal{L}$；
         基学习器数量 $T$；
         子空间属性数 $d'$

    过程：
    1. **for** $t=1,2,\ldots,T$ **do**
    2. $\mathcal{F}_t = \text{RS}(D,d')$
    3. $D_t = \text{Map}_{\mathcal{F}_t}(D)$
    4. $h_t = \mathcal{L}(D_t)$
    5. **end for**

    输出：$H(x) = \arg\max_{y\in\mathcal{Y}}\sum_{t=1}^T \mathbb{1}(h_t(\text{Map}_{\mathcal{F}_t}(x)) = y)$

- 输出表示扰动

此类做法的基本思路是对输出表示进行操纵以增强多样性。可对训练样本的标记进行改动，如"翻转法"(Flipping Output) [Breiman, 2000] 随机改变一些训练样本的标记；也可对输出表示进行转化，如"输出调制法"(Output Smearing) [Breiman, 2000] 将分类输出转化为回归输出后再建立个体学习器；还可将原任务拆解为多个可同时求解的子任务，如 ECOC 法 [Dietterich and Bakiri, 1995] 利用纠错输出码将多分类任务拆解为一系列二分类任务来训练基学习器。

- 算法参数扰动

基学习算法通常都有参数需要进行设置，例如神经网络的隐层神经元数、初始连接权值等，通过随机设置不同的参数，往往可产生差异较大的个体学习器。

例如"负相关法"(Negative Correlation) [Liu and Yao, 1999] 显式地通过正则化项来强制个体神经网络采用不同的参数。对参数敏感的学习算法，在学习过程中某些环节用其他方式代替，从而达到扰动的目的，例如可将决策树使用的属性选择机制替换为随机机制。值得指出的是，使用单一学习器时通常需使用交叉验证等方法来确定参数值，这事实上已使用了多个参数设置训练出多个学习器，只不过最终仅选择其中一个学习器进行使用；而集成学习则相当于把这些学习器都利用起来；由此也可看出，集成学习技术的实际开销并不比使用单一学习器大很多。

不同的多样性增强机制可同时使用，例如 8.3.2 节介绍的随机森林中同时使用了数据样本扰动和输入属性扰动，有些方法本身就同时使用了多种机制 [Zhou, 2012] -->

